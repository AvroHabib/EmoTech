{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8852412,"sourceType":"datasetVersion","datasetId":5328643}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Flatten, Dense,Input,Bidirectional,LSTM,GRU,SimpleRNN,Dropout,LayerNormalization , Concatenate,Conv2D,MaxPooling2D,Layer,BatchNormalization,GlobalMaxPooling1D,Conv1D,Activation, Dot\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom sklearn.utils import class_weight\nimport librosa\nimport numpy as np\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.regularizers import l2\nimport pickle\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import clone_model\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom tensorflow.keras.utils import plot_model\nimport pickle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-04T09:51:46.451251Z","iopub.execute_input":"2024-07-04T09:51:46.451604Z","iopub.status.idle":"2024-07-04T09:51:58.301504Z","shell.execute_reply.started":"2024-07-04T09:51:46.451576Z","shell.execute_reply":"2024-07-04T09:51:58.300702Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-04 09:51:47.873369: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-04 09:51:47.873474: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-04 09:51:47.969767: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"file_path = '/content/drive/MyDrive/padded_mfccs_combined_augmented.pickle'\n\n# Open the file in binary read mode\nwith open(file_path, 'rb') as f:\n    # Load the data from the file\n    mfccs = pickle.load(f)\n\n    \n    \nfile_path = '/content/drive/MyDrive/labels_combined_augmented.pickle'\n\n# Open the file in binary read mode\nwith open(file_path, 'rb') as f:\n    # Load the data from the file\n    labels = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:52:31.462951Z","iopub.execute_input":"2024-07-04T09:52:31.463305Z","iopub.status.idle":"2024-07-04T09:52:31.699437Z","shell.execute_reply.started":"2024-07-04T09:52:31.463276Z","shell.execute_reply":"2024-07-04T09:52:31.698657Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(\n    monitor='val_loss',      # Metric to monitor\n    patience=5,              # Number of epochs with no improvement after which training will be stopped\n    verbose=1,               # Verbosity mode\n    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',     # Metric to monitor\n    factor=0.5,             # Factor by which the learning rate will be reduced\n    patience=3,             # Number of epochs with no improvement after which learning rate will be reduced\n    verbose=1,              # Verbosity mode\n    min_lr=1e-7             # Lower bound on the learning rate\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:52:40.479481Z","iopub.execute_input":"2024-07-04T09:52:40.480109Z","iopub.status.idle":"2024-07-04T09:52:40.485466Z","shell.execute_reply.started":"2024-07-04T09:52:40.480077Z","shell.execute_reply":"2024-07-04T09:52:40.484504Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_mfccs = np.array(mfccs)\ny = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:52:44.847725Z","iopub.execute_input":"2024-07-04T09:52:44.848466Z","iopub.status.idle":"2024-07-04T09:52:45.036817Z","shell.execute_reply.started":"2024-07-04T09:52:44.848422Z","shell.execute_reply":"2024-07-04T09:52:45.035806Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:52:49.017211Z","iopub.execute_input":"2024-07-04T09:52:49.017551Z","iopub.status.idle":"2024-07-04T09:52:49.022750Z","shell.execute_reply.started":"2024-07-04T09:52:49.017523Z","shell.execute_reply":"2024-07-04T09:52:49.021623Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define the input shape\ninput_shape = (740, 13, 1)  # Adding a channel dimension for Conv2D\n\n# Input layer\ninput_layer = Input(shape=input_shape)\n\n# BiLSTM branch\nbilstm_input_model1 = tf.keras.layers.Reshape((740, 13))(input_layer)  # Reshaping for LSTM input\nbilstm1_model1 = Bidirectional(LSTM(64,\n                            return_sequences=True\n                            ))(bilstm_input_model1)\n\n# Add second Bidirectional LSTM layer with regularizations\nbilstm2_model1 = Bidirectional(LSTM(64\n                            ))(bilstm1_model1)\n\n\n# Conv2D branch\nconv2d = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(input_layer)\nconv2d = BatchNormalization()(conv2d)\n\nconv2d = MaxPooling2D(pool_size=(2, 2))(conv2d)\n# dropout1 = Dropout(0.5)(conv2d)\nconv2d = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(conv2d)\nconv2d = BatchNormalization()(conv2d)\nconv2d = MaxPooling2D(pool_size=(2, 2))(conv2d)\n# dropout2 = Dropout(0.5)(conv2d)\nconv2d = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(conv2d)\nconv2d = BatchNormalization()(conv2d)\nconv2d = MaxPooling2D(pool_size=(2, 2))(conv2d)\n# dropout3 = Dropout(0.5)(conv2d)\nconv_flat = Flatten()(conv2d)\ndense1 = Dense(512,activation = 'relu')(conv_flat)\ndropout4 = Dropout(0.2)(dense1)\ndense2 = Dense(128,activation ='relu')(dropout4)\ndropout5 = Dropout(0.2)(dense2)\n# Concatenate BiLSTM and Conv2D branches\nconcatenated = Concatenate()([bilstm2_model1, dropout5])\n\ndense = Dense(64,activation='relu')(concatenated)\noutput_layer = Dense(5, activation='softmax')(dense)\nmodel_speech = Model(inputs=input_layer,outputs=output_layer)\n\nmodel_speech.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Print the summary of the combined model\nmodel_speech.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:52:57.753387Z","iopub.execute_input":"2024-07-04T09:52:57.754050Z","iopub.status.idle":"2024-07-04T09:52:59.093376Z","shell.execute_reply.started":"2024-07-04T09:52:57.754015Z","shell.execute_reply":"2024-07-04T09:52:59.092535Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m740\u001b[0m, \u001b[38;5;34m13\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m740\u001b[0m, \u001b[38;5;34m13\u001b[0m,   │        \u001b[38;5;34m320\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m740\u001b[0m, \u001b[38;5;34m13\u001b[0m,   │        \u001b[38;5;34m128\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m370\u001b[0m, \u001b[38;5;34m6\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m370\u001b[0m, \u001b[38;5;34m6\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m370\u001b[0m, \u001b[38;5;34m6\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m3\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m3\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m3\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m92\u001b[0m, \u001b[38;5;34m1\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11776\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m6,029,824\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m740\u001b[0m, \u001b[38;5;34m13\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m740\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m39,936\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m65,664\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m98,816\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m325\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">740</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">740</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">740</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">370</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">370</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">370</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11776</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">6,029,824</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">740</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">740</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">39,936</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,344,581\u001b[0m (24.20 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,344,581</span> (24.20 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,344,133\u001b[0m (24.20 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,344,133</span> (24.20 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"val_accuracies = []\ntrain_accuracies_per_epoch = []\nval_accuracies_per_epoch = []\ntrain_losses_per_epoch = []\nval_losses_per_epoch = []\n\nfor train_index, val_index in kf.split(X_mfccs):\n    X_mfccs_train, X_mfccs_val = X_mfccs[train_index], X_mfccs[val_index]\n    y_train, y_val = y[train_index], y[val_index]\n\n    history = model_speech.fit(\n        X_mfccs_train,                 # Input data\n        y_train,                       # Labels\n        batch_size=32,                 # Batch size\n        epochs=30,                     # Number of epochs\n        validation_data=(X_mfccs_val, y_val),\n        callbacks=[reduce_lr,early_stopping]\n    )\n    val_accuracy = history.history['val_accuracy'][-1]\n    val_accuracies.append(val_accuracy)\n    print(f\"Fold validation accuracy: {val_accuracy}\")\n\n    # Store the accuracies\n    train_accuracies_per_epoch.append(history.history['accuracy'])\n    val_accuracies_per_epoch.append(history.history['val_accuracy'])\n    train_losses_per_epoch.append(history.history['loss'])\n    val_losses_per_epoch.append(history.history['val_loss'])\n\n\naverage_val_accuracy = np.mean(val_accuracies)\nprint(\"Average Validation Accuracy:\", average_val_accuracy)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:53:39.202263Z","iopub.execute_input":"2024-07-04T09:53:39.202614Z","iopub.status.idle":"2024-07-04T10:06:30.182587Z","shell.execute_reply.started":"2024-07-04T09:53:39.202583Z","shell.execute_reply":"2024-07-04T10:06:30.181710Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 131ms/step - accuracy: 0.2891 - loss: 2.1737 - val_accuracy: 0.4117 - val_loss: 1.3588 - learning_rate: 0.0010\nEpoch 2/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 111ms/step - accuracy: 0.4120 - loss: 1.3553 - val_accuracy: 0.4064 - val_loss: 1.3347 - learning_rate: 0.0010\nEpoch 3/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.4081 - loss: 1.3451 - val_accuracy: 0.4064 - val_loss: 1.3792 - learning_rate: 0.0010\nEpoch 4/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.4460 - loss: 1.3153 - val_accuracy: 0.4534 - val_loss: 1.2573 - learning_rate: 0.0010\nEpoch 5/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.4533 - loss: 1.2383 - val_accuracy: 0.4712 - val_loss: 1.2382 - learning_rate: 0.0010\nEpoch 6/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.4584 - loss: 1.2489 - val_accuracy: 0.4614 - val_loss: 1.2296 - learning_rate: 0.0010\nEpoch 7/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.4904 - loss: 1.2052 - val_accuracy: 0.4650 - val_loss: 1.2287 - learning_rate: 0.0010\nEpoch 8/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.5004 - loss: 1.2030 - val_accuracy: 0.4907 - val_loss: 1.2109 - learning_rate: 0.0010\nEpoch 9/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.5312 - loss: 1.1341 - val_accuracy: 0.4809 - val_loss: 1.2183 - learning_rate: 0.0010\nEpoch 10/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.5079 - loss: 1.1665 - val_accuracy: 0.4854 - val_loss: 1.1894 - learning_rate: 0.0010\nEpoch 11/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.5370 - loss: 1.1006 - val_accuracy: 0.4889 - val_loss: 1.1932 - learning_rate: 0.0010\nEpoch 12/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.5522 - loss: 1.0861 - val_accuracy: 0.5093 - val_loss: 1.1600 - learning_rate: 0.0010\nEpoch 13/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.5628 - loss: 1.0543 - val_accuracy: 0.4862 - val_loss: 1.2274 - learning_rate: 0.0010\nEpoch 14/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.5799 - loss: 1.0206 - val_accuracy: 0.5111 - val_loss: 1.1619 - learning_rate: 0.0010\nEpoch 15/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5985 - loss: 1.0081\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.5984 - loss: 1.0082 - val_accuracy: 0.5084 - val_loss: 1.1814 - learning_rate: 0.0010\nEpoch 16/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6191 - loss: 0.9619 - val_accuracy: 0.5262 - val_loss: 1.1669 - learning_rate: 5.0000e-04\nEpoch 17/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.6510 - loss: 0.8908 - val_accuracy: 0.5448 - val_loss: 1.1332 - learning_rate: 5.0000e-04\nEpoch 18/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6614 - loss: 0.8708 - val_accuracy: 0.5244 - val_loss: 1.1842 - learning_rate: 5.0000e-04\nEpoch 19/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 113ms/step - accuracy: 0.6671 - loss: 0.8496 - val_accuracy: 0.5253 - val_loss: 1.1600 - learning_rate: 5.0000e-04\nEpoch 20/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6900 - loss: 0.7889\nEpoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.6900 - loss: 0.7891 - val_accuracy: 0.5129 - val_loss: 1.2164 - learning_rate: 5.0000e-04\nEpoch 21/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6911 - loss: 0.7777 - val_accuracy: 0.5324 - val_loss: 1.2024 - learning_rate: 2.5000e-04\nEpoch 22/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.7272 - loss: 0.7102 - val_accuracy: 0.5413 - val_loss: 1.2049 - learning_rate: 2.5000e-04\nEpoch 22: early stopping\nRestoring model weights from the end of the best epoch: 17.\nFold validation accuracy: 0.5412600040435791\nEpoch 1/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.6410 - loss: 0.8965 - val_accuracy: 0.6584 - val_loss: 0.9108 - learning_rate: 2.5000e-04\nEpoch 2/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.6519 - loss: 0.8796 - val_accuracy: 0.6495 - val_loss: 0.9019 - learning_rate: 2.5000e-04\nEpoch 3/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6583 - loss: 0.8612 - val_accuracy: 0.6557 - val_loss: 0.8964 - learning_rate: 2.5000e-04\nEpoch 4/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6893 - loss: 0.8142 - val_accuracy: 0.6495 - val_loss: 0.9031 - learning_rate: 2.5000e-04\nEpoch 5/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6883 - loss: 0.7937 - val_accuracy: 0.6371 - val_loss: 0.9231 - learning_rate: 2.5000e-04\nEpoch 6/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6921 - loss: 0.7848\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.6921 - loss: 0.7848 - val_accuracy: 0.6273 - val_loss: 0.9340 - learning_rate: 2.5000e-04\nEpoch 7/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.7088 - loss: 0.7490 - val_accuracy: 0.6398 - val_loss: 0.9345 - learning_rate: 1.2500e-04\nEpoch 8/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.7357 - loss: 0.7017 - val_accuracy: 0.6406 - val_loss: 0.9252 - learning_rate: 1.2500e-04\nEpoch 8: early stopping\nRestoring model weights from the end of the best epoch: 3.\nFold validation accuracy: 0.6406388878822327\nEpoch 1/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 114ms/step - accuracy: 0.6770 - loss: 0.8504 - val_accuracy: 0.7178 - val_loss: 0.7608 - learning_rate: 1.2500e-04\nEpoch 2/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.6758 - loss: 0.8299 - val_accuracy: 0.7152 - val_loss: 0.7615 - learning_rate: 1.2500e-04\nEpoch 3/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.7016 - loss: 0.7866 - val_accuracy: 0.6992 - val_loss: 0.7668 - learning_rate: 1.2500e-04\nEpoch 4/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7042 - loss: 0.7763\nEpoch 4: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.7041 - loss: 0.7765 - val_accuracy: 0.7098 - val_loss: 0.7660 - learning_rate: 1.2500e-04\nEpoch 5/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6970 - loss: 0.7679 - val_accuracy: 0.7045 - val_loss: 0.7643 - learning_rate: 6.2500e-05\nEpoch 6/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.7104 - loss: 0.7643 - val_accuracy: 0.6992 - val_loss: 0.7661 - learning_rate: 6.2500e-05\nEpoch 6: early stopping\nRestoring model weights from the end of the best epoch: 1.\nFold validation accuracy: 0.6992014050483704\nEpoch 1/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 129ms/step - accuracy: 0.6752 - loss: 0.8240 - val_accuracy: 0.7336 - val_loss: 0.7140 - learning_rate: 6.2500e-05\nEpoch 2/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.6757 - loss: 0.8206 - val_accuracy: 0.7282 - val_loss: 0.7174 - learning_rate: 6.2500e-05\nEpoch 3/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6824 - loss: 0.8196 - val_accuracy: 0.7247 - val_loss: 0.7205 - learning_rate: 6.2500e-05\nEpoch 4/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6889 - loss: 0.8090\nEpoch 4: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.6889 - loss: 0.8089 - val_accuracy: 0.7300 - val_loss: 0.7250 - learning_rate: 6.2500e-05\nEpoch 5/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6839 - loss: 0.7829 - val_accuracy: 0.7202 - val_loss: 0.7331 - learning_rate: 3.1250e-05\nEpoch 6/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6972 - loss: 0.7887 - val_accuracy: 0.7229 - val_loss: 0.7260 - learning_rate: 3.1250e-05\nEpoch 6: early stopping\nRestoring model weights from the end of the best epoch: 1.\nFold validation accuracy: 0.7229129672050476\nEpoch 1/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 114ms/step - accuracy: 0.6814 - loss: 0.8122 - val_accuracy: 0.7185 - val_loss: 0.7219 - learning_rate: 3.1250e-05\nEpoch 2/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6825 - loss: 0.8211 - val_accuracy: 0.7194 - val_loss: 0.7207 - learning_rate: 3.1250e-05\nEpoch 3/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.6936 - loss: 0.7914 - val_accuracy: 0.7185 - val_loss: 0.7234 - learning_rate: 3.1250e-05\nEpoch 4/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - accuracy: 0.6920 - loss: 0.8171 - val_accuracy: 0.7123 - val_loss: 0.7259 - learning_rate: 3.1250e-05\nEpoch 5/30\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6971 - loss: 0.7780\nEpoch 5: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.6971 - loss: 0.7781 - val_accuracy: 0.7131 - val_loss: 0.7269 - learning_rate: 3.1250e-05\nEpoch 5: early stopping\nRestoring model weights from the end of the best epoch: 1.\nFold validation accuracy: 0.7131438851356506\nAverage Validation Accuracy: 0.6634314298629761\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Assuming you have a test dataset X_test and true labels y_true\n# Make predictions on the test dataset\npredictions = model_speech.predict(X_mfccs_val)\n\n# Convert predicted probabilities to class labels\npredicted_classes = np.argmax(predictions, axis=-1)\n\n# Convert true labels to class labels\ntrue_classes = np.argmax(y_val, axis=-1)\n\n# Check the shapes of predicted_classes and true_classes\nprint(\"Shapes of predicted_classes and true_classes:\")\nprint(predicted_classes.shape)\nprint(true_classes.shape)\n\n# Calculate overall accuracy\noverall_accuracy = np.mean(predicted_classes == true_classes)\nprint(f\"\\nOverall Accuracy: {overall_accuracy}\")\n\n# If necessary, calculate class-wise accuracy\nif len(np.unique(true_classes)) > 1:\n    # Calculate class-wise accuracy\n    class_accuracy = {}\n    for class_label in range(5):  # Assuming num_classes is the number of classes (5 in your case)\n        # Indices where true labels match the current class label\n        class_indices = np.where(true_classes == class_label)[0]\n\n        # Indices where predicted labels match the current class label\n        correct_indices = np.where(predicted_classes[class_indices] == class_label)[0]\n\n        # Calculate accuracy for the current class\n        if len(class_indices) > 0:\n            accuracy = len(correct_indices) / len(class_indices)\n        else:\n            accuracy = 0.0\n\n        # Store class-wise accuracy\n        class_accuracy[class_label] = accuracy\n\n    # Display or store class-wise accuracy\n    print(\"\\nClass-wise Accuracy:\")\n    for class_label, accuracy in class_accuracy.items():\n        print(f\"Class {class_label}: Accuracy {accuracy}\")\nelse:\n    print(\"\\nClass-wise accuracy calculation is not applicable because there is only one class present.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:23:27.698555Z","iopub.execute_input":"2024-07-04T10:23:27.699415Z","iopub.status.idle":"2024-07-04T10:23:30.184963Z","shell.execute_reply.started":"2024-07-04T10:23:27.699379Z","shell.execute_reply":"2024-07-04T10:23:30.184017Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step\nShapes of predicted_classes and true_classes:\n(1126,)\n(1126,)\n\nOverall Accuracy: 0.7184724689165186\n\nClass-wise Accuracy:\nClass 0: Accuracy 0.7873303167420814\nClass 1: Accuracy 0.7102803738317757\nClass 2: Accuracy 0.7280334728033473\nClass 3: Accuracy 0.5855855855855856\nClass 4: Accuracy 0.7782608695652173\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Calculate classification report\nreport = classification_report(true_classes, predicted_classes, digits=4)\n\n# Print the classification report\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:23:41.689758Z","iopub.execute_input":"2024-07-04T10:23:41.690106Z","iopub.status.idle":"2024-07-04T10:23:41.707055Z","shell.execute_reply.started":"2024-07-04T10:23:41.690079Z","shell.execute_reply":"2024-07-04T10:23:41.706213Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n           0     0.8131    0.7873    0.8000       221\n           1     0.7600    0.7103    0.7343       214\n           2     0.7699    0.7280    0.7484       239\n           3     0.5394    0.5856    0.5616       222\n           4     0.7306    0.7783    0.7537       230\n\n    accuracy                         0.7185      1126\n   macro avg     0.7226    0.7179    0.7196      1126\nweighted avg     0.7230    0.7185    0.7201      1126\n\n","output_type":"stream"}]}]}